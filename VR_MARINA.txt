INFO:root:Step=1, accuracy=0.104, loss=2.3547301292419434, gradient_norm=12.692666053771973
INFO:root:Step=51, accuracy=0.162, loss=2.4164371490478516, gradient_norm=103.33716583251953
INFO:root:Step=101, accuracy=0.194, loss=2.3019723892211914, gradient_norm=93.29635620117188
INFO:root:Step=151, accuracy=0.246, loss=2.1640372276306152, gradient_norm=84.80656433105469
INFO:root:Step=201, accuracy=0.262, loss=2.0890941619873047, gradient_norm=90.97393035888672
INFO:root:Step=251, accuracy=0.3, loss=1.9898765087127686, gradient_norm=89.37389373779297
INFO:root:Step=301, accuracy=0.344, loss=1.912850260734558, gradient_norm=87.40778350830078
INFO:root:Step=351, accuracy=0.356, loss=1.8583983182907104, gradient_norm=94.52568817138672
INFO:root:Step=401, accuracy=0.398, loss=1.74749755859375, gradient_norm=86.91015625
INFO:root:Step=451, accuracy=0.428, loss=1.6842093467712402, gradient_norm=89.09247589111328
INFO:root:Step=501, accuracy=0.438, loss=1.6147403717041016, gradient_norm=86.52252960205078
INFO:root:Step=551, accuracy=0.454, loss=1.5827805995941162, gradient_norm=88.3529052734375
INFO:root:Step=601, accuracy=0.468, loss=1.5331467390060425, gradient_norm=83.22518920898438
INFO:root:Step=651, accuracy=0.482, loss=1.4945018291473389, gradient_norm=91.56291961669922
INFO:root:Step=701, accuracy=0.496, loss=1.4528837203979492, gradient_norm=84.13056182861328
INFO:root:Step=751, accuracy=0.522, loss=1.413671851158142, gradient_norm=83.39541625976562
INFO:root:Step=801, accuracy=0.528, loss=1.3690177202224731, gradient_norm=87.08304595947266
INFO:root:Step=851, accuracy=0.548, loss=1.342133641242981, gradient_norm=83.66873931884766
INFO:root:Step=901, accuracy=0.556, loss=1.3069790601730347, gradient_norm=81.41030883789062
INFO:root:Step=951, accuracy=0.584, loss=1.270516276359558, gradient_norm=80.64041137695312
INFO:root:Step=1001, accuracy=0.574, loss=1.2584881782531738, gradient_norm=85.64306640625
INFO:root:Step=1051, accuracy=0.58, loss=1.20705246925354, gradient_norm=79.69329833984375
INFO:root:Step=1101, accuracy=0.604, loss=1.192376971244812, gradient_norm=79.30591583251953
INFO:root:Step=1151, accuracy=0.59, loss=1.1721653938293457, gradient_norm=86.39622497558594
INFO:root:Step=1201, accuracy=0.628, loss=1.1419944763183594, gradient_norm=81.57229614257812
INFO:root:Step=1251, accuracy=0.63, loss=1.1164524555206299, gradient_norm=88.2640151977539
INFO:root:Step=1301, accuracy=0.632, loss=1.1081340312957764, gradient_norm=88.42540740966797
INFO:root:Step=1351, accuracy=0.64, loss=1.0888009071350098, gradient_norm=86.03536224365234
INFO:root:Step=1401, accuracy=0.626, loss=1.0712900161743164, gradient_norm=96.63143157958984
INFO:root:Step=1451, accuracy=0.664, loss=1.0431900024414062, gradient_norm=89.75254821777344
INFO:root:Step=1501, accuracy=0.662, loss=1.0095521211624146, gradient_norm=80.00428009033203
INFO:root:Step=1551, accuracy=0.664, loss=1.0036194324493408, gradient_norm=90.08804321289062
INFO:root:Step=1601, accuracy=0.674, loss=0.9747231006622314, gradient_norm=82.74774169921875
INFO:root:Step=1651, accuracy=0.662, loss=0.9642113447189331, gradient_norm=83.16435241699219
INFO:root:Step=1701, accuracy=0.666, loss=0.9711664915084839, gradient_norm=91.54058837890625
INFO:root:Step=1751, accuracy=0.672, loss=0.9366501569747925, gradient_norm=92.19163513183594
INFO:root:Step=1801, accuracy=0.678, loss=0.9155047535896301, gradient_norm=87.26519012451172
